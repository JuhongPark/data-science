{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4-박주홍\n",
    "## Setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "라이브러리를 로드합니다. 주요 라이브러리로 pandas, numpy와 sklearn을 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required modules\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function\n",
    "분석에 사용할 함수를 정의합니다. 함수의 역할에 대해서는 아래 한글 주석으로 추가하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습 결과를 다양한 Metric으로 평가하는 함수, 아래 주석을 통해 평가하는 13가지 Metric에 대해 설명하고 있음\n",
    "def calculate_diagnostic_performance (actual_predicted):\n",
    "    \"\"\" Calculate diagnostic performance.\n",
    "    \n",
    "    Takes a Numpy array of 1 and zero, two columns: actual and predicted\n",
    "    \n",
    "    Note that some statistics are repeats with different names\n",
    "    (precision = positive_predictive_value and recall = sensitivity).\n",
    "    Both names are returned\n",
    "    \n",
    "    Returns a dictionary of results:\n",
    "        \n",
    "    1) accuracy: proportion of test results that are correct    \n",
    "    2) sensitivity: proportion of true +ve identified\n",
    "    3) specificity: proportion of true -ve identified\n",
    "    4) positive likelihood: increased probability of true +ve if test +ve\n",
    "    5) negative likelihood: reduced probability of true +ve if test -ve\n",
    "    6) false positive rate: proportion of false +ves in true -ve patients\n",
    "    7) false negative rate:  proportion of false -ves in true +ve patients\n",
    "    8) positive predictive value: chance of true +ve if test +ve\n",
    "    9) negative predictive value: chance of true -ve if test -ve\n",
    "    10) precision = positive predictive value \n",
    "    11) recall = sensitivity\n",
    "    12) f1 = (2 * precision * recall) / (precision + recall)\n",
    "    13) positive rate = rate of true +ve (not strictly a performance measure)\n",
    "    \"\"\"\n",
    "    # Calculate results\n",
    "    actual_positives = actual_predicted[:, 0] == 1\n",
    "    actual_negatives = actual_predicted[:, 0] == 0\n",
    "    test_positives = actual_predicted[:, 1] == 1\n",
    "    test_negatives = actual_predicted[:, 1] == 0\n",
    "    test_correct = actual_predicted[:, 0] == actual_predicted[:, 1]\n",
    "    accuracy = np.average(test_correct)\n",
    "    true_positives = actual_positives & test_positives\n",
    "    true_negatives = actual_negatives & test_negatives\n",
    "    sensitivity = np.sum(true_positives) / np.sum(actual_positives)\n",
    "    specificity = np.sum(true_negatives) / np.sum(actual_negatives)\n",
    "    positive_likelihood = sensitivity / (1 - specificity)\n",
    "    negative_likelihood = (1 - sensitivity) / specificity\n",
    "    false_positive_rate = 1 - specificity\n",
    "    false_negative_rate = 1 - sensitivity\n",
    "    positive_predictive_value = np.sum(true_positives) / np.sum(test_positives)\n",
    "    negative_predictive_value = np.sum(true_negatives) / np.sum(test_negatives)\n",
    "    precision = positive_predictive_value\n",
    "    recall = sensitivity\n",
    "    f1 = (2 * precision * recall) / (precision + recall)\n",
    "    positive_rate = np.mean(actual_predicted[:,1])\n",
    "    \n",
    "    # Add results to dictionary\n",
    "    performance = {}\n",
    "    performance['accuracy'] = accuracy\n",
    "    performance['sensitivity'] = sensitivity\n",
    "    performance['specificity'] = specificity\n",
    "    performance['positive_likelihood'] = positive_likelihood\n",
    "    performance['negative_likelihood'] = negative_likelihood\n",
    "    performance['false_positive_rate'] = false_positive_rate\n",
    "    performance['false_negative_rate'] = false_negative_rate\n",
    "    performance['positive_predictive_value'] = positive_predictive_value\n",
    "    performance['negative_predictive_value'] = negative_predictive_value\n",
    "    performance['precision'] = precision\n",
    "    performance['recall'] = recall\n",
    "    performance['f1'] = f1\n",
    "    performance['positive_rate'] = positive_rate\n",
    "\n",
    "    return performance\n",
    "\n",
    "# 데이터를 로드하는 함수, 주석으로 데이터에 대한 설명이 추가됨\n",
    "def load_data ():\n",
    "    \"\"\"Load the data set. Here we load the Breast Cancer Wisconsin (Diagnostic)\n",
    "    Data Set. Data could be loaded from other sources though the structure\n",
    "    should be compatible with thi sdata set, that is an object with the \n",
    "    following attribtes:\n",
    "        .data (holds feature data)\n",
    "        .feature_names (holds feature titles)\n",
    "        .target_names (holds outcome classification names)\n",
    "        .target (holds classification as zero-based number)\n",
    "        .DESCR (holds text-based description of data set)\"\"\"\n",
    "    \n",
    "    data_set = datasets.load_breast_cancer()\n",
    "    return data_set\n",
    "\n",
    "# 학습을 안정적으로 하기 위해 feature의 scale을 보정하여 normalise하는 코드\n",
    "def normalise (X_train,X_test):\n",
    "    \"\"\"Normalise X data, so that training set has mean of zero and standard\n",
    "    deviation of one\"\"\"\n",
    "    \n",
    "    # Initialise a new scaling object for normalising input data\n",
    "    sc=StandardScaler()\n",
    "    \n",
    "    # Set up the scaler just on the training set\n",
    "    sc.fit(X_train)\n",
    "    \n",
    "    # Apply the scaler to the training and test sets\n",
    "    X_train_std=sc.transform(X_train)\n",
    "    X_test_std=sc.transform(X_test)\n",
    "    \n",
    "    return X_train_std, X_test_std\n",
    "\n",
    "# 학습 결과를 보기 편하게 출력하는 함수\n",
    "def print_diagnostic_results (performance):\n",
    "    \"\"\"Iterate through, and print, the performance metrics dictionary\"\"\"\n",
    "    \n",
    "    print('\\nMachine learning diagnostic performance measures:')\n",
    "    print('-------------------------------------------------')\n",
    "    for key, value in performance.items():\n",
    "        print (key,'= %0.3f' %value) # print 3 decimal places\n",
    "    return\n",
    "\n",
    "# 학습 결과로 나오는 feature importances를 출력하는 함수\n",
    "def print_feaure_importances (model, features):\n",
    "    print ()\n",
    "    print ('Feature importances:')\n",
    "    print ('--------------------')\n",
    "    df = pd.DataFrame()\n",
    "    df['feature'] = features\n",
    "    df['importance'] = model.feature_importances_\n",
    "    df = df.sort_values('importance', ascending = False)\n",
    "    print (df)\n",
    "    return\n",
    "\n",
    "# 학습과 평가에 사용하기 위해 데이터를 X, y 로 나누고 이를 Train 및 Test로 나누하는 함수\n",
    "def split_data (data_set, split=0.25):\n",
    "    \"\"\"Extract X and y data from data_set object, and split into tarining and\n",
    "    test data. Split defaults to 75% training, 25% test if not other value \n",
    "    passed to function\"\"\"\n",
    "    \n",
    "    X=data_set.data\n",
    "    y=data_set.target\n",
    "    X_train,X_test,y_train,y_test=train_test_split(\n",
    "        X,y,test_size=split, random_state=0)\n",
    "    return X_train,X_test,y_train,y_test\n",
    "\n",
    "# 모델로 Test를 하는 함수, 입력값에 대한 예측값을 출력함\n",
    "def test_model(model, X, y):\n",
    "    \"\"\"Return predicted y given X (attributes)\"\"\"\n",
    "    \n",
    "    y_pred = model.predict(X)\n",
    "    test_results = np.vstack((y, y_pred)).T\n",
    "    return test_results\n",
    "\n",
    "# 모델을 Train 하는 함수, 학습된 모델을 출력함\n",
    "# Reproducible한 결과를 위해 random_state는 0으로 지정\n",
    "def train_model (X, y):\n",
    "    \"\"\"Train the model \"\"\"\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    model = RandomForestClassifier(n_estimators=10000,\n",
    "                                random_state=0,\n",
    "                                n_jobs=-1)\n",
    "    model.fit (X,y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "실제 분석을 하는 항목입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Machine learning diagnostic performance measures:\n",
      "-------------------------------------------------\n",
      "accuracy = 0.972\n",
      "sensitivity = 0.967\n",
      "specificity = 0.981\n",
      "positive_likelihood = 51.233\n",
      "negative_likelihood = 0.034\n",
      "false_positive_rate = 0.019\n",
      "false_negative_rate = 0.033\n",
      "positive_predictive_value = 0.989\n",
      "negative_predictive_value = 0.945\n",
      "precision = 0.989\n",
      "recall = 0.967\n",
      "f1 = 0.978\n",
      "positive_rate = 0.615\n",
      "\n",
      "Feature importances:\n",
      "--------------------\n",
      "                    feature  importance\n",
      "22          worst perimeter    0.128502\n",
      "7       mean concave points    0.122821\n",
      "27     worst concave points    0.121434\n",
      "23               worst area    0.102040\n",
      "20             worst radius    0.099788\n",
      "6            mean concavity    0.054834\n",
      "2            mean perimeter    0.046540\n",
      "3                 mean area    0.039068\n",
      "13               area error    0.039064\n",
      "0               mean radius    0.036952\n",
      "26          worst concavity    0.034057\n",
      "25        worst compactness    0.017705\n",
      "10             radius error    0.016905\n",
      "21            worst texture    0.016596\n",
      "1              mean texture    0.014762\n",
      "5          mean compactness    0.013044\n",
      "12          perimeter error    0.012706\n",
      "24         worst smoothness    0.012666\n",
      "28           worst symmetry    0.012059\n",
      "29  worst fractal dimension    0.006879\n",
      "16          concavity error    0.006393\n",
      "4           mean smoothness    0.005968\n",
      "17     concave points error    0.005948\n",
      "19  fractal dimension error    0.005639\n",
      "11            texture error    0.005319\n",
      "15        compactness error    0.005317\n",
      "8             mean symmetry    0.004822\n",
      "18           symmetry error    0.004448\n",
      "14         smoothness error    0.004105\n",
      "9    mean fractal dimension    0.003617\n"
     ]
    }
   ],
   "source": [
    "###### Main code #######\n",
    "\n",
    "# 데이터를 로드\n",
    "# Load data\n",
    "data_set = load_data()\n",
    "\n",
    "# 데이터를 X, y에 대해 train, test로 나눔\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = split_data(data_set, 0.25)\n",
    "\n",
    "# Normalise 를 진행하는 부분이나 Random Forest Classification 에서는 필요하지 않으므로 주석화 되어 있음\n",
    "# Tree Regression 등 직접 수치로 Cost를 계산하는 경우가 아닌 Tree Classfication의 경우,\n",
    "# 보통 Normalise 가 학습에 영향을 주지 않으므로 이 경우 Normalise 하지 않아도 무방함\n",
    "# Normalise data (not needed for Random Forests)\n",
    "# X_train_std, X_test_std = normalise(X_train,X_test)\n",
    "\n",
    "# 모델을 학습\n",
    "# Train model\n",
    "model = train_model(X_train, y_train)\n",
    "\n",
    "# Test 데이터에 대한 모델 예측 결과를 생성\n",
    "# Produce results for test set\n",
    "test_results = test_model(model, X_test, y_test)\n",
    "\n",
    "# Test 데이터에 대한 모델 예측 결과를 바탕으로 각종 Metric 생성\n",
    "# Measure performance of test set predictions\n",
    "performance = calculate_diagnostic_performance(test_results)\n",
    "\n",
    "# 위에서 생성된 모델 Metric을 출력\n",
    "# Print performance metrics\n",
    "print_diagnostic_results(performance)\n",
    "\n",
    "# Random Forest의 Feature Importances 출력\n",
    "# Random Forest에서 각 Feature에 의한 Cost(Tree Classification에서는 주로 GINI Impurity, Cross Entropy 등 사용)\n",
    "# 감소 효과를 측정하여 개별 Feature의 Importance를 평가하기 위해 사용\n",
    "# Print feature importances\n",
    "print_feaure_importances (model, data_set.feature_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
