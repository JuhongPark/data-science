{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5-박주홍\n",
    "## Setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "라이브러리를 로드합니다. 주요 라이브러리로 numpy와 sklearn을 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required modules\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function\n",
    "분석에 사용할 함수를 정의합니다. 함수의 역할에 대해서는 아래 한글 주석으로 추가하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습 결과를 다양한 Metric으로 평가하는 함수, 아래 주석을 통해 평가하는 13가지 Metric에 대해 설명하고 있음\n",
    "def calculate_diagnostic_performance (actual_predicted):\n",
    "    \"\"\" Calculate diagnostic performance.\n",
    "    \n",
    "    Takes a Numpy array of 1 and zero, two columns: actual and predicted\n",
    "    \n",
    "    Note that some statistics are repeats with different names\n",
    "    (precision = positive_predictive_value and recall = sensitivity).\n",
    "    Both names are returned\n",
    "    \n",
    "    Returns a dictionary of results:\n",
    "        \n",
    "    1) accuracy: proportion of test results that are correct    \n",
    "    2) sensitivity: proportion of true +ve identified\n",
    "    3) specificity: proportion of true -ve identified\n",
    "    4) positive likelihood: increased probability of true +ve if test +ve\n",
    "    5) negative likelihood: reduced probability of true +ve if test -ve\n",
    "    6) false positive rate: proportion of false +ves in true -ve patients\n",
    "    7) false negative rate:  proportion of false -ves in true +ve patients\n",
    "    8) positive predictive value: chance of true +ve if test +ve\n",
    "    9) negative predictive value: chance of true -ve if test -ve\n",
    "    10) precision = positive predictive value \n",
    "    11) recall = sensitivity\n",
    "    12) f1 = (2 * precision * recall) / (precision + recall)\n",
    "    13) positive rate = rate of true +ve (not strictly a performance measure)\n",
    "    \"\"\"\n",
    "    # Calculate results\n",
    "    actual_positives = actual_predicted[:, 0] == 1\n",
    "    actual_negatives = actual_predicted[:, 0] == 0\n",
    "    test_positives = actual_predicted[:, 1] == 1\n",
    "    test_negatives = actual_predicted[:, 1] == 0\n",
    "    test_correct = actual_predicted[:, 0] == actual_predicted[:, 1]\n",
    "    accuracy = np.average(test_correct)\n",
    "    true_positives = actual_positives & test_positives\n",
    "    true_negatives = actual_negatives & test_negatives\n",
    "    sensitivity = np.sum(true_positives) / np.sum(actual_positives)\n",
    "    specificity = np.sum(true_negatives) / np.sum(actual_negatives)\n",
    "    positive_likelihood = sensitivity / (1 - specificity)\n",
    "    negative_likelihood = (1 - sensitivity) / specificity\n",
    "    false_positive_rate = 1 - specificity\n",
    "    false_negative_rate = 1 - sensitivity\n",
    "    positive_predictive_value = np.sum(true_positives) / np.sum(test_positives)\n",
    "    negative_predictive_value = np.sum(true_negatives) / np.sum(test_negatives)\n",
    "    precision = positive_predictive_value\n",
    "    recall = sensitivity\n",
    "    f1 = (2 * precision * recall) / (precision + recall)\n",
    "    positive_rate = np.mean(actual_predicted[:,1])\n",
    "    \n",
    "    # Add results to dictionary\n",
    "    performance = {}\n",
    "    performance['accuracy'] = accuracy\n",
    "    performance['sensitivity'] = sensitivity\n",
    "    performance['specificity'] = specificity\n",
    "    performance['positive_likelihood'] = positive_likelihood\n",
    "    performance['negative_likelihood'] = negative_likelihood\n",
    "    performance['false_positive_rate'] = false_positive_rate\n",
    "    performance['false_negative_rate'] = false_negative_rate\n",
    "    performance['positive_predictive_value'] = positive_predictive_value\n",
    "    performance['negative_predictive_value'] = negative_predictive_value\n",
    "    performance['precision'] = precision\n",
    "    performance['recall'] = recall\n",
    "    performance['f1'] = f1\n",
    "    performance['positive_rate'] = positive_rate\n",
    "\n",
    "    return performance\n",
    "\n",
    "# 데이터를 로드하는 함수, 주석으로 데이터에 대한 설명이 추가됨\n",
    "def load_data ():\n",
    "    \"\"\"Load the data set. Here we load the Breast Cancer Wisconsin (Diagnostic)\n",
    "    Data Set. Data could be loaded from other sources though the structure\n",
    "    should be compatible with thi sdata set, that is an object with the \n",
    "    following attribtes:\n",
    "        .data (holds feature data)\n",
    "        .feature_names (holds feature titles)\n",
    "        .target_names (holds outcome classification names)\n",
    "        .target (holds classification as zero-based number)\n",
    "        .DESCR (holds text-based description of data set)\"\"\"\n",
    "    \n",
    "    data_set = datasets.load_breast_cancer()\n",
    "    return data_set\n",
    "\n",
    "# 학습을 안정적으로 하기 위해 feature의 scale을 보정하여 normalise하는 코드\n",
    "def normalise (X_train,X_test):\n",
    "    \"\"\"Normalise X data, so that training set has mean of zero and standard\n",
    "    deviation of one\"\"\"\n",
    "    \n",
    "    # Initialise a new scaling object for normalising input data\n",
    "    sc=StandardScaler()\n",
    "    \n",
    "    # Set up the scaler just on the training set\n",
    "    sc.fit(X_train)\n",
    "    \n",
    "    # Apply the scaler to the training and test sets\n",
    "    X_train_std=sc.transform(X_train)\n",
    "    X_test_std=sc.transform(X_test)\n",
    "    \n",
    "    return X_train_std, X_test_std\n",
    "\n",
    "# 학습 결과를 보기 편하게 출력하는 함수\n",
    "def print_diagnostic_results (performance):\n",
    "    \"\"\"Iterate through, and print, the performance metrics dictionary\"\"\"\n",
    "    \n",
    "    print('\\nMachine learning diagnostic performance measures:')\n",
    "    print('-------------------------------------------------')\n",
    "    for key, value in performance.items():\n",
    "        print (key,'= %0.3f' %value) # print 3 decimal places\n",
    "    return\n",
    "\n",
    "# 학습과 평가에 사용하기 위해 데이터를 X, y 로 나누고 이를 Train 및 Test로 나누하는 함수\n",
    "def split_data (data_set, split=0.25):\n",
    "    \"\"\"Extract X and y data from data_set object, and split into tarining and\n",
    "    test data. Split defaults to 75% training, 25% test if not other value \n",
    "    passed to function\"\"\"\n",
    "    \n",
    "    X=data_set.data\n",
    "    y=data_set.target\n",
    "    X_train,X_test,y_train,y_test=train_test_split(\n",
    "        X,y,test_size=split, random_state=0)\n",
    "    return X_train,X_test,y_train,y_test\n",
    "\n",
    "# 모델로 Test를 하는 함수, 입력값에 대한 예측값을 출력함\n",
    "def test_model(model, X, y):\n",
    "    \"\"\"Return predicted y given X (attributes)\"\"\"\n",
    "    \n",
    "    y_pred = model.predict(X)\n",
    "    test_results = np.vstack((y, y_pred)).T\n",
    "    return test_results\n",
    "\n",
    "# 모델을 Train 하는 함수, 학습된 모델을 출력함\n",
    "# Reproducible한 결과를 위해 random_state는 0으로 지정\n",
    "# 학습을 위해 solver로 Limited-memory BFGS를 사용함\n",
    "# 모델 구조는 hidden layer (50,5) 으로 하였고 activation으로 relu를 사용하였음\n",
    "def train_model (X, y):\n",
    "    \"\"\"Train the model \"\"\"\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    model = MLPClassifier(solver='lbfgs', alpha=1e-8, hidden_layer_sizes=(50, 5),\n",
    "                        max_iter=100000, shuffle=True, learning_rate_init=0.001,\n",
    "                        activation='relu', learning_rate='constant', tol=1e-7,\n",
    "                        random_state=0)\n",
    "    model.fit(X_train_std, y_train)   \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "실제 분석을 하는 항목입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Machine learning diagnostic performance measures:\n",
      "-------------------------------------------------\n",
      "accuracy = 0.958\n",
      "sensitivity = 0.967\n",
      "specificity = 0.943\n",
      "positive_likelihood = 17.078\n",
      "negative_likelihood = 0.035\n",
      "false_positive_rate = 0.057\n",
      "false_negative_rate = 0.033\n",
      "positive_predictive_value = 0.967\n",
      "negative_predictive_value = 0.943\n",
      "precision = 0.967\n",
      "recall = 0.967\n",
      "f1 = 0.967\n",
      "positive_rate = 0.629\n"
     ]
    }
   ],
   "source": [
    "###### Main code #######\n",
    "\n",
    "# 데이터를 로드\n",
    "# Load data\n",
    "data_set = load_data()\n",
    "\n",
    "# 데이터를 X, y에 대해 train, test로 나눔\n",
    "# Split data into trainign and test sets\n",
    "X_train, X_test, y_train, y_test = split_data(data_set, 0.25)\n",
    "\n",
    "# 안정적인 학습을 위해 Feature들의 sclae 차이를 보정하는 Normalize 수행\n",
    "# Normalise data\n",
    "X_train_std, X_test_std = normalise(X_train,X_test)\n",
    "\n",
    "# 모델을 학습\n",
    "# Train model\n",
    "model = train_model(X_train_std,y_train)\n",
    "\n",
    "# Test 데이터에 대한 모델 예측 결과를 생성\n",
    "# Produce results for test set\n",
    "test_results = test_model(model, X_test_std, y_test)\n",
    "\n",
    "# Test 데이터에 대한 모델 예측 결과를 바탕으로 각종 Metric 생성\n",
    "# Measure performance of test set predictions\n",
    "performance = calculate_diagnostic_performance(test_results)\n",
    "\n",
    "# 위에서 생성된 모델 Metric을 출력\n",
    "# Print performance metrics\n",
    "print_diagnostic_results(performance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
