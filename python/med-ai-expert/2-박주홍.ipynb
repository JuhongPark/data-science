{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-박주홍\n",
    "## Setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "라이브러리를 로드합니다. 주요 라이브러리로 pandas와 sklearn을 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터를 로드합니다. 데이터의 정보를 간단하게 살펴봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data fields data set:\n",
      "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
      "\n",
      "Classification outcomes:\n",
      "['malignant' 'benign']\n"
     ]
    }
   ],
   "source": [
    "# Load Dataset\n",
    "data_set = datasets.load_breast_cancer()\n",
    "X = data_set.data\n",
    "y = data_set.target\n",
    "\n",
    "# Show data fields\n",
    "print('Data fields data set:')\n",
    "print(data_set.feature_names)\n",
    "\n",
    "# Show classifications\n",
    "print('\\nClassification outcomes:')\n",
    "print(data_set.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습을 위해 데이터를 Split 합니다. Train와 Test로 분류하여 학습과 평가에 사용합니다. Test의 크기는 0.25로 합니다. Reproducible 한 결과를 위해 split에 사용할 random seed(random_state)는 0으로 지정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and test data sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습을 잘하기 위해 standard scaler를 사용합니다. 이렇게 하면 Feature들의 Scale에 의한 효과가 보정되어서 안정적으로 학습이 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise a new scaling object for normalising input data\n",
    "sc = StandardScaler() \n",
    "\n",
    "# Set up the scaler just on the training set\n",
    "sc.fit(X_train)\n",
    "\n",
    "# Apply the scaler to the training and test sets\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습을 합니다. Penalty 파라미터(C)로 100을 주었으며 Penalty는 Overfitting을 막는 효과가 있습니다. Reproducible한 결과를 위해 random_state는 위와 동일하게 0으로 지정하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jpark/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=0, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run logistic regression model from sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(C=100,random_state=0)\n",
    "lr.fit(X_train_std,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 결과를 출력합니다. 여기서는 Accuracy를 계산합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Percent Accuracy: 93.7\n"
     ]
    }
   ],
   "source": [
    "y_pred = lr.predict(X_test_std)\n",
    "\n",
    "correct = (y_test == y_pred).sum()\n",
    "incorrect = (y_test != y_pred).sum()\n",
    "accuracy = correct / (correct + incorrect) * 100\n",
    "\n",
    "print('\\nPercent Accuracy: %0.1f' %accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 결과를 직접 확인하기 위해 각 데이터에 대한 결과과 실제 값, 예측 여부를 보여줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detailed results for first 20 tests:\n",
      "       actual  predicted  correct\n",
      "0   malignant  malignant     True\n",
      "1      benign     benign     True\n",
      "2      benign     benign     True\n",
      "3      benign     benign     True\n",
      "4      benign     benign     True\n",
      "5      benign     benign     True\n",
      "6      benign     benign     True\n",
      "7      benign     benign     True\n",
      "8      benign     benign     True\n",
      "9      benign     benign     True\n",
      "10     benign     benign     True\n",
      "11     benign     benign     True\n",
      "12     benign     benign     True\n",
      "13     benign  malignant    False\n",
      "14     benign     benign     True\n",
      "15  malignant  malignant     True\n",
      "16     benign     benign     True\n",
      "17  malignant  malignant     True\n",
      "18  malignant  malignant     True\n",
      "19  malignant  malignant     True\n"
     ]
    }
   ],
   "source": [
    "# Show more detailed results\n",
    "\n",
    "prediction = pd.DataFrame()\n",
    "prediction['actual'] = data_set.target_names[y_test]\n",
    "prediction['predicted'] = data_set.target_names[y_pred]\n",
    "prediction['correct'] = prediction['actual'] == prediction['predicted']\n",
    "\n",
    "print ('\\nDetailed results for first 20 tests:')\n",
    "print (prediction.head(20))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
